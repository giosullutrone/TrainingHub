{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gio\\miniconda3\\envs\\prompteffectiveness\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch import bfloat16\n",
    "\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\", torch_dtype=bfloat16, device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris?\"}, \n",
    "                {\"role\": \"assistant\", \"content\": \"gg\"}]\n",
    "tools = None\n",
    "\n",
    "tool_use_prompt = tokenizer.apply_chat_template(\n",
    "            conversation,\n",
    "            tools=tools,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>user\\nWhat's the weather like in Paris?<|im_end|>\\n<|im_start|>assistant\\ngg<|im_end|>\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_use_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gio\\miniconda3\\envs\\prompteffectiveness\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import fields, field, dataclass, asdict\n",
    "import argparse\n",
    "from typing import Union\n",
    "from ast import literal_eval\n",
    "from typing import Dict, Union, Optional\n",
    "from datasets import DatasetDict, Dataset, IterableDatasetDict, IterableDataset\n",
    "from recipes.Recipe import Recipe\n",
    "from cookbooks import DATASET_COOKBOOK\n",
    "\n",
    "@dataclass\n",
    "class DatasetRecipe(Recipe):\n",
    "    \"\"\"Kwargs to give to the \"load_dataset\" function from \"datasets\" module\"\"\"\n",
    "    dataset_load: Optional[dict] = field(default=None, metadata={\"description\": \"test\"})\n",
    "    response_template: Optional[str] = field(default=None)\n",
    "\n",
    "    def preprocess_dataset(self, dataset: Union[DatasetDict, Dataset, IterableDatasetDict, IterableDataset, None]) -> Union[DatasetDict, Dataset, IterableDatasetDict, IterableDataset, None]:\n",
    "        return dataset\n",
    "    \n",
    "    def preprocess_function(self, sample: Dict, examples: Union[DatasetDict, Dataset, IterableDatasetDict, IterableDataset, dict, None]) -> Dict:\n",
    "        return sample\n",
    "\n",
    "class ModelRecipe(Recipe):\n",
    "    model_load: Optional[dict] = None\n",
    "    model_config: Optional[dict] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataclasses(dataclass_list):\n",
    "    # Convert each dataclass in the list to a dictionary with its metadata\n",
    "    dicts_with_metadata = []\n",
    "    for cls in dataclass_list:\n",
    "        fis = {fi.name: fi.type for fi in asdict(cls.__annotations__.values())}\n",
    "        metadata = {\"created_at\": getattr(cls, \"created_at\", 0)}\n",
    "        dicts_with_metadata.append({**fis, **metadata})\n",
    "\n",
    "    # Merge the dictionaries together\n",
    "    merged_dict = {}\n",
    "    for d in dicts_with_metadata:\n",
    "        merged_dict.update(d)\n",
    "\n",
    "    return merged_dict\n",
    "\n",
    "# Define a function to convert the merged dictionary back into a dataclass\n",
    "def dict_to_dataclass(cls, data):\n",
    "    annotations = {k: v for k, v in cls.__annotations__.items() if k not in [\"created_at\", \"source\"]}\n",
    "    data = {**annotations, **data}\n",
    "    return cls(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DatasetRecipe' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmerge_dataclasses\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mDatasetRecipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mModelRecipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m, in \u001b[0;36mmerge_dataclasses\u001b[1;34m(dataclass_list)\u001b[0m\n\u001b[0;32m      3\u001b[0m dicts_with_metadata \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataclass_list:\n\u001b[1;32m----> 5\u001b[0m     fis \u001b[38;5;241m=\u001b[39m {fi\u001b[38;5;241m.\u001b[39mname: fi\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m fi \u001b[38;5;129;01min\u001b[39;00m asdict(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mvalues()}\n\u001b[0;32m      6\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)}\n\u001b[0;32m      7\u001b[0m     dicts_with_metadata\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata})\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DatasetRecipe' object is not callable"
     ]
    }
   ],
   "source": [
    "merge_dataclasses([DatasetRecipe(), ModelRecipe()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset_recipe DATASET_RECIPE]\n",
      "                             [--dataset_load DATASET_LOAD]\n",
      "                             [--response_template RESPONSE_TEMPLATE]\n",
      "                             [--model_recipe MODEL_RECIPE]\n",
      "                             [--model_load MODEL_LOAD]\n",
      "                             [--model_config MODEL_CONFIG]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --dataset_recipe DATASET_RECIPE\n",
      "                        Recipe's name from cookbook\n",
      "  --dataset_load DATASET_LOAD\n",
      "                        test\n",
      "  --response_template RESPONSE_TEMPLATE\n",
      "  --model_recipe MODEL_RECIPE\n",
      "                        Recipe's name from cookbook\n",
      "  --model_load MODEL_LOAD\n",
      "  --model_config MODEL_CONFIG\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# Here we define all the parameters for our training procedure (\"train_cli.py\")\n",
    "# Each parameter is a field. For each of them we specify the type, default and some useful metadata.\n",
    "# \n",
    "# Metadata:\n",
    "#   - `description` (str): Description of the field. Used both as documentation and also by the argument parser\n",
    "#                          as information to show when calling `--help` on `train_cli.py` \n",
    "#   - `required` (bool): Whether it is required for running `train_cli.py`. \n",
    "#                        Note: This is done instead of removing `None` from (Union[..., None]) so that we can use also\n",
    "#                              use a starting config file for common parameters (See utils.parsers.get_config_from_argparser for the code)\n",
    "#   - `recipe_keywords` (List[str]): List of optional fields' names to use to create the recipe in case it was specified as a string.\n",
    "#                           For example --model_recipe \"MistralModelRecipe\" will also use `model_load` and `model_config` fields for initialization.\n",
    "#   - `cookbook` (CookBook): Cookbook to use to get the `recipe` if it was specified by string. \n",
    "#                            For example --model_recipe \"MistralModelRecipe\", the string \"MistralModelRecipe\" would be used to get the \n",
    "#                            class from the given cookbook.\n",
    "# --------------------------------------------------------------------------\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "def camel_to_snake(camel_string):\n",
    "    \"\"\"\n",
    "    Convert camelCase string to snake_case string.\n",
    "\n",
    "    Args:\n",
    "        camel_string (str): The input string in camelCase format.\n",
    "\n",
    "    Returns:\n",
    "        str: The output string in snake_case format.\n",
    "    \"\"\"\n",
    "    result = ''\n",
    "    for i, char in enumerate(camel_string):\n",
    "        if char.isupper() and i > 0:\n",
    "            result += '_' + char.lower()\n",
    "        else:\n",
    "            result += char.lower()\n",
    "    return result\n",
    "\n",
    "def generate_argparser_from_recipe(recipe_dataclasses: List[object], description: str):\n",
    "    \"\"\"\n",
    "    Generate an argparse.ArgumentParser based on the fields of a dataclass.\n",
    "\n",
    "    Args:\n",
    "        dataclass_type: Type of the dataclass.\n",
    "        description (str): Description for the argument parser.\n",
    "\n",
    "    Returns:\n",
    "        argparse.ArgumentParser: Argument parser populated with dataclass fields.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=description)\n",
    "\n",
    "    for recipe_dataclass in recipe_dataclasses:\n",
    "        parser.add_argument(f\"--{camel_to_snake(recipe_dataclass.__name__)}\", \n",
    "                            type=str, default=None, \n",
    "                            help=\"Recipe's name from cookbook\")\n",
    "        \n",
    "        # Iterate through fields of the dataclass\n",
    "        for field in fields(recipe_dataclass):\n",
    "            field_type = field.type\n",
    "            # Handle Optional types\n",
    "            if hasattr(field_type, \"__origin__\") and field_type.__origin__ is Optional:\n",
    "                valid_types = [t for t in field_type.__args__ if t in (str, int, dict, float)]\n",
    "                field_type = valid_types[0]\n",
    "                # If type is dict, we make the argparse evaluate the string\n",
    "                # This converts the string '{\"example\": \"example value\"}' into the final dict\n",
    "                if field_type == dict: field_type = literal_eval\n",
    "            field_default = field.default if field.default is not None else None\n",
    "            field_help = field.metadata.get(\"description\", \"\")\n",
    "            parser.add_argument(f\"--{field.name}\", type=field_type, default=field_default, help=field_help)\n",
    "\n",
    "    return parser\n",
    "\n",
    "print(generate_argparser_from_recipe([DatasetRecipe, ModelRecipe], \"\").print_help())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_load': typing.Optional[dict],\n",
       " 'response_template': typing.Optional[str]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetRecipe.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict, dataclass\n",
    "from pprint import pprint\n",
    "\n",
    "def join_dicts(priority: Optional[dict], secondary: Optional[dict]) -> Dict:\n",
    "    if not secondary: secondary = {}\n",
    "    if not priority: priority = {}\n",
    "    return {**secondary, **priority}\n",
    "\n",
    "@dataclass\n",
    "class DatasetRecipe(Recipe):\n",
    "    \"\"\"Kwargs to give to the \"load_dataset\" function from \"datasets\" module\"\"\"\n",
    "    dataset_load: Optional[dict] = field(default=None, metadata={\"description\": \"test\"})\n",
    "    response_template: Optional[str] = field(default=None)\n",
    "\n",
    "@dataclass\n",
    "class ModelRecipe(Recipe):\n",
    "    model_load: Optional[dict] = None\n",
    "    model_config: Optional[dict] = None\n",
    "\n",
    "# @dataclass\n",
    "# class RecipeMerge:\n",
    "#     def _update_fields(self, field_dict: dict):\n",
    "#         self.__dataclass_fields__.update(field_dict)\n",
    "#     \n",
    "#     def __init__(self, recipe_dataclasses: List[dataclass]):\n",
    "#         for recipe_dataclass in recipe_dataclasses:\n",
    "#             self._update_fields(recipe_dataclass.__dataclass_fields__)\n",
    "#             \n",
    "#             # For some reason the field does not appear unless we modify an already existing one\n",
    "#             fi = fields(recipe_dataclass)[0]\n",
    "#             fi.name = camel_to_snake(recipe_dataclass.__name__)\n",
    "#             fi.default = None; fi.type = str\n",
    "#             fi.metadata = {\"required\": True, \"cookbook\": \"\", \"recipe_keywords\": fields(recipe_dataclass)}\n",
    "#             self._update_fields({camel_to_snake(recipe_dataclass.__name__): fi})\n",
    "# \n",
    "# t = RecipeMerge([DatasetRecipe, ModelRecipe])\n",
    "\n",
    "# pprint(t.__dataclass_fields__)\n",
    "\n",
    "# for fi in fields(t):\n",
    "#     print(fi.name, fi.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Field(name='dataset_load',type=Field(name='dataset_load',type=typing.Optional[dict],default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'description': 'test'}),kw_only=False,_field_type=_FIELD),default=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       " Field(name='response_template',type=Field(name='response_template',type=typing.Optional[str],default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),default=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       " Field(name='dataset_recipe',type=Field(name=None,type=None,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'required': True, 'cookbook': '', 'recipe_keywords': (Field(name='dataset_load',type=typing.Optional[dict],default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'description': 'test'}),kw_only=False,_field_type=_FIELD), Field(name='response_template',type=typing.Optional[str],default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD))}),kw_only=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,_field_type=None),default=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       " Field(name='model_load',type=Field(name='model_load',type=typing.Optional[dict],default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),default=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       " Field(name='model_config',type=Field(name='model_config',type=typing.Optional[dict],default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),default=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),\n",
       " Field(name='model_recipe',type=Field(name=None,type=None,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'required': True, 'cookbook': '', 'recipe_keywords': (Field(name='model_load',type=typing.Optional[dict],default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD), Field(name='model_config',type=typing.Optional[dict],default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD))}),kw_only=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,_field_type=None),default=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,default_factory=<dataclasses._MISSING_TYPE object at 0x0000014DAAA6AB00>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import make_dataclass\n",
    "\n",
    "def get_config(recipe_dataclasses: List[Tuple[dataclass, bool, Cookbook]]):\n",
    "    fis = []\n",
    "    for recipe, required, cookbook in [(DatasetRecipe, True, DATASET_COOKBOOK), ModelRecipe]:\n",
    "        fis += [(x.name, x) for x in fields(recipe)]\n",
    "        fis += [(camel_to_snake(recipe.__name__), field(default=None, metadata = {\"required\": required, \n",
    "                                                                            \"cookbook\": cookbook, \n",
    "                                                                            \"recipe_keywords\": fields(recipe)}))]\n",
    "    make_dataclass(\"Config\", fields=fis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompteffectiveness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
